{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b90579-bc6c-4a16-a2b2-072b66872c83",
   "metadata": {},
   "source": [
    "# U Net Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676b76e-a617-4bf8-ae96-cd788a851f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Adam Optimizer\n",
    "# \n",
    "\"\"\"\n",
    "Created on Thu Feb 13 22:24:51 2024\n",
    "\n",
    "@author: Dheepak\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2DTranspose, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb35ea-797d-4688-9c76-e4638d33cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "SIZE_X = 128\n",
    "SIZE_Y = 128\n",
    "\n",
    "train_images = []\n",
    "\n",
    "image_paths = glob.glob(\"E:/MICCAI Dataset/Training set/Images/*.png\")\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    filename = (img_path.split(\"Images\\\\\")[1]).split(\".\")[0]\n",
    "    masks_path = f\"E:/MICCAI Dataset/Training set/Masks/{filename}.png\"\n",
    "    \n",
    "    masks = cv2.imread(masks_path, 0)\n",
    "    masks = cv2.resize(masks, (SIZE_Y, SIZE_X))\n",
    "\n",
    "    if masks is None:\n",
    "        print(f\"Failed to load mask: {masks_path}\")\n",
    "        continue\n",
    "\n",
    "    # Append the image and mask to the list\n",
    "    train_images.append(img)\n",
    "    train_images.append(masks)\n",
    "\n",
    "# Check the length of the list\n",
    "print(len(train_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94f99f-51b3-42fd-9265-72201833b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806091b-e79f-4539-8b65-d238111b924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207e27d-daed-4996-b5ce-d43e6519f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_masks = [] \n",
    "for directory_path in glob.glob(\"E:\\\\MICCAI Dataset\\\\Training Set\\\\Masks\"):\n",
    "    #print('hi')\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (128, 128), interpolation = cv2.INTER_NEAREST) \n",
    "        masks_arr = np.array(mask)\n",
    "        length = len(np.unique(masks_arr))\n",
    "        #if len(np.unique(masks_arr))==4:\n",
    "            #print(np.unique(masks_arr), mask_path)\n",
    "          \n",
    "        if length ==4:\n",
    "            mask[mask==0] = 1\n",
    "            mask[mask==85] = 2 \n",
    "            mask[mask==170] = 3\n",
    "            mask[mask==255] = 4\n",
    "        elif length==3:\n",
    "            mask[mask==0] = 1\n",
    "            if 85 in np.unique(masks_arr):\n",
    "                mask[mask==85]=2\n",
    "                mask[mask==170]=3\n",
    "            elif 170 in np.unique(masks_arr):\n",
    "                mask[mask==170]= 2\n",
    "                mask[mask==255]= 4\n",
    "            else:\n",
    "                mask[mask==127]= 2\n",
    "                mask[mask==255]= 3\n",
    "        elif length==2:\n",
    "            mask[mask==0] = 1\n",
    "            mask[mask==255] = 2\n",
    "        else:\n",
    "            mask[mask==0] = 1\n",
    "        #Otherwise ground truth changes due to interpolation\n",
    "        train_masks.append(mask)\n",
    "        \n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d8ec0-2a02-4f37-b1dd-2f31e46e268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416c3dd-7722-4037-a34d-e8f40c6eaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8491e-57fa-42c1-9fd8-087f6031bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb93c0-c859-4ed4-af51-15663020873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_masks_encoded_original_shape)\n",
    "train_images = np.expand_dims(train_images, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af758b1d-b67c-42fa-9b4d-20b090bbcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = normalize(train_images, axis=1)\n",
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35aaa5-0c9f-4cb5-8ce8-b9924307c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20bd62-3892-47ac-9c2a-71a25a695643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255311b1-e8a1-49f6-bf87-b625c2b4f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73473a4a-1e5f-4665-b2b8-19ede4c97279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd227b8-85c6-403b-b33a-d475be04e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af96236-28cb-4118-a3c3-5db2f381b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a8b5d-8011-420c-b903-131770bf7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "def get_model():\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc429ba-3120-4ae2-9414-e64dae3e0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    callbacks=[early_stopping],\n",
    "                    #class_weight=class_weights,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889b175-c59d-4026-bbce-5dc255825119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('categorical_1.hdf5')\n",
    "#model.save('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')\n",
    "############################################################\n",
    "#Evaluate the model\n",
    "\t# evaluate model\n",
    "_, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636681a2-5438-4d5e-8efa-737009e61367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42977bc3-28aa-4cc0-bb72-adbd44122238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights('categorical_2.hdf5')  \n",
    "#model.load_weights('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')  \n",
    "\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a0f3f-d8a1-43e7-8249-76551cb16609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af303772-a02e-4600-a5b6-ec06f3138871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_img_number =  random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test_cat[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720595e1-8bb3-43be-b85c-07652b708265",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ccfe5-c228-4382-8584-a01469cff319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "#Calculate IoU for all test images and average\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc64080-9025-4ae7-bef5-2c0d89536032",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccards=[]\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    \n",
    "    smooth=1\n",
    "    intersection=K.sum(K.abs(y_true*y_pred),axis=-1)\n",
    "    union=K.sum(y_true,-1)+K.sum(y_pred,-1)-intersection\n",
    "    iou=K.mean((intersection+smooth)/(union+smooth),axis=0)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d219fc-6df6-4e86-93f8-e5a9285ff4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    jacard=0\n",
    "    for i in range(4):\n",
    "    \n",
    "        jacard=jacard_coef(y_true[:,:,:,i], y_pred[:,:,:,i])\n",
    "        jaccards.append(jacard)\n",
    "    return np.mean(jaccards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262afe06-16ac-4d46-a285-1097f72dca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dices=[]\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float64')\n",
    "    y_pred = K.cast(y_pred, 'float64')\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912c794-9306-4d6a-887c-0451459d94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918903a7-960b-4691-9c04-d1510cb1cc72",
   "metadata": {},
   "source": [
    "## Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6993755-6543-44d0-b7b2-23b61e58007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "SIZE_X = 128\n",
    "SIZE_Y = 128\n",
    "\n",
    "def load_images_and_masks(directory_path):\n",
    "    images = []\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def load_masks_and_convert(directory_path):\n",
    "    masks = []\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation=cv2.INTER_NEAREST)\n",
    "        masks_arr = np.array(mask)\n",
    "        length = len(np.unique(masks_arr))\n",
    "        if length == 4:\n",
    "            mask[mask == 0] = 1\n",
    "            mask[mask == 85] = 2\n",
    "            mask[mask == 170] = 3\n",
    "            mask[mask == 255] = 4\n",
    "        elif length == 3:\n",
    "            mask[mask == 0] = 1\n",
    "            if 85 in np.unique(masks_arr):\n",
    "                mask[mask == 85] = 2\n",
    "                mask[mask == 170] = 3\n",
    "            elif 170 in np.unique(masks_arr):\n",
    "                mask[mask == 170] = 2\n",
    "                mask[mask == 255] = 4\n",
    "            else:\n",
    "                mask[mask == 127] = 2\n",
    "                mask[mask == 255] = 3\n",
    "        elif length == 2:\n",
    "            mask[mask == 0] = 1\n",
    "            mask[mask == 255] = 2\n",
    "        else:\n",
    "            mask[mask == 0] = 1\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e7e13-bc3a-42ec-b288-b79fa71fa1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing images and masks\n",
    "test_images = load_images_and_masks(\"E:/MICCAI Dataset/Testing Set/Test_images\")\n",
    "test_masks = load_masks_and_convert(\"E:/MICCAI Dataset/Testing Set/Test_masks\")\n",
    "test_images = np.array(test_images)\n",
    "test_masks = np.array(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea52117-0f78-4c4f-b8a8-7502ce7157de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load validation images and masks\n",
    "val_images = load_images_and_masks(\"E:/MICCAI Dataset/Validation Set/Validation_Images\")\n",
    "val_masks = load_masks_and_convert(\"E:/MICCAI Dataset/Validation Set/Validation_Masks\")\n",
    "val_images = np.array(val_images)\n",
    "val_masks = np.array(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad1d00-2843-4eec-87ad-02199079b312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape masks to 1D arrays\n",
    "y_val_flat = val_masks.flatten()\n",
    "y_test_flat = test_masks.flatten()\n",
    "\n",
    "y_val_flat[y_val_flat == 1] = 0\n",
    "y_val_flat[y_val_flat == 2] = 1\n",
    "y_val_flat[y_val_flat == 3] = 2\n",
    "y_val_flat[y_val_flat == 4] = 3\n",
    "\n",
    "y_test_flat[y_test_flat == 1] = 0\n",
    "y_test_flat[y_test_flat == 2] = 1\n",
    "y_test_flat[y_test_flat == 3] = 2\n",
    "y_test_flat[y_test_flat == 4] = 3\n",
    "\n",
    "# Convert to one-hot encoded format\n",
    "y_val_one_hot = to_categorical(y_val_flat, num_classes=4)\n",
    "y_test_one_hot = to_categorical(y_test_flat, num_classes=4)\n",
    "\n",
    "# Reshape back to original shape if needed\n",
    "y_val_one_hot = y_val_one_hot.reshape(val_masks.shape[0], val_masks.shape[1], val_masks.shape[2], 4)\n",
    "y_test_one_hot = y_test_one_hot.reshape(test_masks.shape[0], test_masks.shape[1], test_masks.shape[2], 4)\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(val_images, y_val_one_hot, verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(test_images, y_test_one_hot, verbose=0)\n",
    "\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1e094-9b54-41e9-9daa-f4d454186184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693e592-5400-444d-abe4-9a88d543dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc192ab1-d666-4bbc-a41b-8adbf07f9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddf9ae-ebc5-432a-89c4-ddb7c19bf913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "output_path = 'E:/MICCAI Dataset/Predicted_masks'\n",
    "\n",
    "# Function to calculate Dice coefficient\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
    "\n",
    "# Loop over each image in the test set\n",
    "for img in range(0, X_test.shape[0]):\n",
    "    temp_img = X_test[img]\n",
    "    ground_truth1 = y_test_cat[img]\n",
    "    temp_img_input = np.expand_dims(temp_img, 0)\n",
    "    ground_truth = np.expand_dims(ground_truth1, 0)\n",
    "    prediction = (model.predict(temp_img_input)).astype('float32')\n",
    "    print(dice_coef(ground_truth, prediction))\n",
    "    predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Plot original image\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(temp_img)\n",
    "\n",
    "    # Plot ground truth label for each class\n",
    "    for i in range(ground_truth1.shape[-1]):\n",
    "        plt.subplot(2, 3, i+2)\n",
    "        plt.title(f'Ground Truth Class {i}')\n",
    "        plt.imshow(ground_truth1[:,:,i], cmap='gray')\n",
    "\n",
    "    # Plot predicted image\n",
    "    plt.subplot(236)\n",
    "    plt.title('Predicted Image')\n",
    "    plt.imshow(predicted_img, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86ddfe-02f2-4cf8-a2f6-62d95910a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Assuming the 'E:/MICCAI Dataset/Predicted_masks' directory exists\n",
    "\n",
    "# Path to save the predicted masks\n",
    "output_path = 'E:/MICCAI Dataset/Predicted_masks'\n",
    "\n",
    "# Loop over each image in the test set\n",
    "for img in range(0, test_images.shape[0]):\n",
    "    temp_img = test_images[img]\n",
    "    temp_img_input = np.expand_dims(temp_img, 0)\n",
    "    prediction = model.predict(temp_img_input).astype('float32')\n",
    "    predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Plot original image\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(temp_img)\n",
    "\n",
    "    # Plot predicted image\n",
    "    plt.subplot(236)\n",
    "    plt.title('Predicted Image')\n",
    "    plt.imshow(predicted_img, cmap='gray')\n",
    "\n",
    "    # Save predicted image\n",
    "    image_name = f'predicted_{img}.png'\n",
    "    image_path = os.path.join(output_path, image_name)\n",
    "    plt.imsave(image_path, predicted_img, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd7478-4cb4-4d07-8ca9-2ffc2c06b696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f57e3-fab8-479a-8027-21aecf677382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img in range(0, X_test.shape[0]):\n",
    "    temp_img = X_test[img]\n",
    "    ground_truth1 = y_test_cat[img]\n",
    "    temp_img_input = np.expand_dims(temp_img, 0)\n",
    "    ground_truth = np.expand_dims(ground_truth1, 0)\n",
    "    prediction = (model.predict(temp_img_input)).astype('float32')\n",
    "    print(dice_coef(ground_truth, prediction))\n",
    "    predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Plot original image\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(temp_img)\n",
    "\n",
    "    # Plot ground truth label for each class\n",
    "    for i in range(ground_truth1.shape[-1]):\n",
    "        plt.subplot(2, 3, i+2)\n",
    "        plt.title(f'Ground Truth Class {i}')\n",
    "        plt.imshow(ground_truth1[:,:,i], cmap='gray')\n",
    "\n",
    "    # Plot predicted image\n",
    "    plt.subplot(236)\n",
    "    plt.title('Predicted Image')\n",
    "    plt.imshow(predicted_img, cmap='gray')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb61800-757e-427b-ad5c-94af67144023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "y_true_indicator = tf.keras.utils.to_categorical(y_test_cat, num_classes=4)\n",
    "y_pred_indicator = tf.keras.utils.to_categorical(np.argmax(y_pred, axis=3), num_classes=4)\n",
    "\n",
    "# Calculate Jaccard score\n",
    "jacard = jaccard_score(y_true_indicator.reshape(-1), y_pred_indicator.reshape(-1), average='macro')\n",
    "print(jacard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a12fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-5):\n",
    "    intersection = np.sum(y_true * y_pred, axis=(1,2,3))\n",
    "    sum_of_squares_pred = np.sum(np.square(y_pred), axis=(1,2,3))\n",
    "    sum_of_squares_true = np.sum(np.square(y_true), axis=(1,2,3))\n",
    "    dice = 1 - (2 * intersection + smooth) / (sum_of_squares_pred + sum_of_squares_true + smooth)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "# Compile the model with focal loss\n",
    "model.compile(optimizer='adam', loss=dice_loss(y_true,y_pred), metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed05d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    callbacks=[early_stopping],\n",
    "                    #class_weight=class_weights,\n",
    "                    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69cf3e7-84ad-4690-8529-5e6d3aa721b0",
   "metadata": {},
   "source": [
    "# Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11d910-9ade-4570-91e3-b95f3b36f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Calculate cross entropy for each channel\n",
    "        cross_entropy = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        \n",
    "        # Calculate the modulating factor for each channel\n",
    "        y_pred_prob = tf.nn.softmax(y_pred, axis=-1)\n",
    "        p_t = tf.reduce_sum(y_true * y_pred_prob, axis=-1)\n",
    "        modulating_factor = (1.0 - p_t)**gamma\n",
    "        \n",
    "        # Calculate the final focal loss for each channel\n",
    "        focal_loss = alpha * modulating_factor * cross_entropy\n",
    "        \n",
    "        # Average the loss over all channels\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "    \n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff173c-e8c5-4c91-872e-93ab30f41ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model = get_model()\n",
    "\n",
    "# Compile the model with focal loss\n",
    "model.compile(optimizer='adam', loss=focal_loss(), metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9a256-d119-47c6-9f6c-a62b0d0a6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    #class_weight=class_weights,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc8f7c2-440c-4c4a-92ba-6d5d7760e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('focal_1.hdf5')\n",
    "#model.save('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')\n",
    "############################################################\n",
    "#Evaluate the model\n",
    "\t# evaluate model\n",
    "_, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc073fd-ffb2-49b7-8151-b576514f4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e0299-7367-4683-a1cf-4a33767b159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights('focal_1.hdf5')  \n",
    "#model.load_weights('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')  \n",
    "\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f83ec-b907-4ae0-9a2f-899dbcf02721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fee026f-05d2-4bdc-886f-56d7d909ecec",
   "metadata": {},
   "source": [
    "## Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74229567-d40f-48ab-8caa-dfa0c02685e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from skimage import io\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path to testing masks and predicted masks\n",
    "test_mask_path = 'E:/MICCAI Dataset/Testing Set/Test_masks'\n",
    "predicted_mask_path = 'E:/MICCAI Dataset/Predicted_masks'\n",
    "\n",
    "# Mapping of class labels to class names\n",
    "class_names = {0: 'BG', 1: 'LV', 2: 'MYO', 3: 'RV'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd1d98-3026-4810-8528-22123815371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import cv2\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "def hausdorff_distance(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate the Hausdorff distance between two multi-class images.\n",
    "\n",
    "    Args:\n",
    "    - image1 (numpy.ndarray): The first multi-class image.\n",
    "    - image2 (numpy.ndarray): The second multi-class image.\n",
    "\n",
    "    Returns:\n",
    "    - float: The Hausdorff distance between the two images.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for label in range(0, 4):  # Assuming 4 classes\n",
    "        mask1 = (image1 == label)\n",
    "        mask2 = (image2 == label)\n",
    "        if np.sum(mask1) == 0 or np.sum(mask2) == 0:\n",
    "            continue\n",
    "        distance = scipy.ndimage.morphology.distance_transform_edt(~mask1)\n",
    "        distance_transformed = distance[mask2]\n",
    "        distances.append(np.max(distance_transformed))\n",
    "    if len(distances) == 0:\n",
    "        return 0\n",
    "    return np.max(distances)\n",
    "\n",
    "def label_test_mask(mask):\n",
    "    mask_resized = mask.astype(np.uint8)\n",
    "    \n",
    "    length = len(np.unique(mask_resized))\n",
    "    if length == 4:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        mask_resized[mask_resized == 85] = 1\n",
    "        mask_resized[mask_resized == 170] = 2\n",
    "        mask_resized[mask_resized == 255] = 3\n",
    "    elif length == 3:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        if 85 in np.unique(mask_resized):\n",
    "            mask_resized[mask_resized == 85] = 1\n",
    "            mask_resized[mask_resized == 170] = 2\n",
    "        elif 170 in np.unique(mask_resized):\n",
    "            mask_resized[mask_resized == 170] = 1\n",
    "            mask_resized[mask_resized == 255] = 3\n",
    "        else:\n",
    "            mask_resized[mask_resized == 127] = 1\n",
    "            mask_resized[mask_resized == 255] = 2\n",
    "    elif length == 2:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        mask_resized[mask_resized == 255] = 1\n",
    "    else:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "    \n",
    "    return mask_resized\n",
    "\n",
    "\n",
    "def resize_and_label_mask(mask):\n",
    "    mask_resized = transform.resize(mask, (128, 128), order=0, anti_aliasing=False, preserve_range=True)\n",
    "    mask_resized = mask_resized.astype(np.uint8)\n",
    "    \n",
    "    length = len(np.unique(mask_resized))\n",
    "    if length == 4:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        mask_resized[mask_resized == 85] = 1\n",
    "        mask_resized[mask_resized == 170] = 2\n",
    "        mask_resized[mask_resized == 255] = 3\n",
    "    elif length == 3:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        if 85 in np.unique(mask_resized):\n",
    "            mask_resized[mask_resized == 85] = 1\n",
    "            mask_resized[mask_resized == 170] = 2\n",
    "        elif 170 in np.unique(mask_resized):\n",
    "            mask_resized[mask_resized == 170] = 1\n",
    "            mask_resized[mask_resized == 255] = 3\n",
    "        else:\n",
    "            mask_resized[mask_resized == 127] = 1\n",
    "            mask_resized[mask_resized == 255] = 2\n",
    "    elif length == 2:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "        mask_resized[mask_resized == 255] = 1\n",
    "    else:\n",
    "        mask_resized[mask_resized == 0] = 0\n",
    "    \n",
    "    return mask_resized\n",
    "\n",
    "# Paths to directories\n",
    "test_images_dir = 'E:/MICCAI Dataset/Testing Set/Test_images'\n",
    "test_masks_dir = 'E:/MICCAI Dataset/Testing Set/Test_masks'\n",
    "predicted_masks_dir = 'E:/MICCAI Dataset/Predicted_masks'\n",
    "\n",
    "# List files in test_masks_dir\n",
    "test_mask_files = os.listdir(test_masks_dir)\n",
    "\n",
    "# Initialize Hausdorff distances list\n",
    "hausdorff_distances = []\n",
    "\n",
    "for test_mask_file in test_mask_files:\n",
    "    # Load test mask and resize\n",
    "    test_mask_path = os.path.join(test_masks_dir, test_mask_file)\n",
    "    test_mask = cv2.imread(test_mask_path)\n",
    "    test_mask_resized = transform.resize(test_mask, (128, 128), order=0, anti_aliasing=False, preserve_range=True)\n",
    "    test_mask_resized = test_mask_resized.astype(np.uint8)\n",
    "    \n",
    "    # Label test mask\n",
    "    test_mask_resized_labeled = label_test_mask(test_mask_resized)\n",
    "\n",
    "    # Load corresponding test image\n",
    "    test_image_path = os.path.join(test_images_dir, test_mask_file.replace('_mask', ''))\n",
    "    test_image = io.imread(test_image_path)\n",
    "\n",
    "    # Extract index from test_mask_file to load corresponding predicted mask\n",
    "    index = int(test_mask_file.split('_')[-1].split('.')[0])\n",
    "    predicted_mask_name = f\"predicted_{index}\"\n",
    "    predicted_mask_path = os.path.join(predicted_masks_dir, predicted_mask_name + '.png')\n",
    "    predicted_mask = cv2.imread(predicted_mask_path)\n",
    "\n",
    "    \n",
    "    predicted_mask = transform.resize(predicted_mask, (128, 128), order=0, anti_aliasing=False, preserve_range=True)\n",
    "    predicted_mask_resized = label_test_mask(predicted_mask)\n",
    "\n",
    "    # Calculate and append Hausdorff distance\n",
    "    hausdorff_distance_value = hausdorff_distance(test_mask_resized, predicted_mask_resized)\n",
    "    #print(f\"Hausdorff distance for {test_mask_file}: {hausdorff_distance_value}\")\n",
    "    hausdorff_distances.append(hausdorff_distance_value)\n",
    "\n",
    "\n",
    "# Calculate mean Hausdorff distance\n",
    "mean_hausdorff_distance = np.mean(hausdorff_distances)\n",
    "\n",
    "# Print mean Hausdorff distance\n",
    "print(f\"Mean Hausdorff Distance: {mean_hausdorff_distance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aaa203-d566-462f-8a4f-2117f9aee9cd",
   "metadata": {},
   "source": [
    "# Jaccord Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a105f9-2a8d-4a92-b901-836dc5ea0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd4e13-4594-499a-ae94-2acb9aa4d469",
   "metadata": {},
   "source": [
    "# Dice Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116c5fc-4977-4912-8f1a-16dea1323637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
